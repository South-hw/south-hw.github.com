<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.1.1">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2020-11-22T22:38:20+09:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">SouthHW Blog</title><subtitle>Deep Learning, Machine Learning, Computer Vision</subtitle><author><name>Nam Hyeon Woo</name></author><entry><title type="html">CAM, GRAD-CAM</title><link href="http://localhost:4000/review%20of%20paper/paper-review-cam/" rel="alternate" type="text/html" title="CAM, GRAD-CAM" /><published>2020-11-22T00:00:00+09:00</published><updated>2020-11-22T00:00:00+09:00</updated><id>http://localhost:4000/review%20of%20paper/paper-review-cam</id><content type="html" xml:base="http://localhost:4000/review%20of%20paper/paper-review-cam/">&lt;h2 id=&quot;cam&quot;&gt;CAM&lt;/h2&gt;

&lt;h5 id=&quot;paper&quot;&gt;Paper&lt;/h5&gt;
&lt;p&gt;Zhou, Bolei, et al. “Learning Deep Features for Discriminative Localization”, CVPR, 2016&lt;/p&gt;

&lt;h5 id=&quot;proposition&quot;&gt;Proposition&lt;/h5&gt;
&lt;p&gt;CAM (Class Activation Map)는 weakly-supervised object localizatoin입니다. Weakly-supervised learning이란 strong supervision이 
아닌 weak supervision으로 네트워크를 학습시키는 것입니다. Segmentation과 같은 localization의 경우 annotation 비용이 classification task에 
비해서 더 많이 든다는 것을 직관적으로 알 수 있습니다. 이 논문에서는 classification task를 통해서 object localization할 수 있는 것을 제안합니다. 
또한 score에 기여한 features와 weights를 이용하여 MAP을 생성하므로 Explainable AI로도 생각할 수 있습니다.&lt;/p&gt;

&lt;h5 id=&quot;method&quot;&gt;Method&lt;/h5&gt;
&lt;p&gt;&lt;img src=&quot;/assets/imgs/cam.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;위 그림처엄 네트워크가 “conv - GAP - classifier”인 경우에 해당 score가 나오도록 기여한 weights를 알 수 있습니다. GAP, Score는 다음 식으로 표현할 수 있습니다.
$$
F^k = \Sigma_{x,y} f_k(x,y)
$$
$$
S_c = \underset{k}\Sigma w_k^c \underset{x,y}\Sigma f_k(x,y).
$$
논문에서는 두 식을 합성하여 논문에서는 CAM을 다음으로 표현합니다. 
$$
M_c (x,y) = \underset{k}\Sigma w_k^c f_k(x,y).
$$&lt;/p&gt;

&lt;h2 id=&quot;grad_cam&quot;&gt;Grad_CAM&lt;/h2&gt;

&lt;h5 id=&quot;paper-1&quot;&gt;Paper&lt;/h5&gt;
&lt;p&gt;Selvaraju, Ramprasaath R., et al. “Grad-CAM: Visual Explanations from Deep Networks via Gradient-based Localization”, ICCV, 2017&lt;/p&gt;

&lt;h5 id=&quot;proposition-1&quot;&gt;Proposition&lt;/h5&gt;
&lt;p&gt;Grad-CAM은 CAM의 generalization version 입니다. CAM은 네트워크 구조가 “conv - global pooling - classifier”에만 적용할 수 있지만 Grad-CAM
은 다양한 네트워크 구조에 적용할 수 있습니다. 그 이유는 Grad-CAM은 Loss로부터 gradient를 계산하기 때문입니다. 논문에서는 Guided Grad-CAM도 소개하지만 
Grad-CAM만 포스팅하겠습니다.&lt;/p&gt;

&lt;h5 id=&quot;method-1&quot;&gt;Method&lt;/h5&gt;
&lt;p&gt;CAM에서 $w_k^c$를 importance라고 하며, socre에 기여한 features의 중요도를 나타냅니다. Grad-CAM에서는 importance를 다음과 같이 계산합니다.
$$
\alpha_k^c = \frac{1}{Z} \sum_{i} \sum_{j} \frac{\partial y^c}{\partial A^k_{ij}}.
$$ 
즉 importance는 output을 features 픽셀마다 각각 gradient를 계산한 후 x,y 좌표로 더해주는 것입니다. importance는 구하고자하는 features의 채널만큼 
나오게 됩니다. 최종적으로 features와 importance를 곱한 후 ReLU function으로 Grad-CAM은 표현됩니다.
$$
L^c_{Grad-CAM} = ReLU(\sum_{k} \alpha^c_k A^k).
$$&lt;/p&gt;

&lt;h5 id=&quot;etc&quot;&gt;etc&lt;/h5&gt;
&lt;p&gt;이후에 weakly object localization과 관련하여 다양한 논문이 나왔습니다. 다양한 논문에서 서로 비교하고 SOTA가 나왔겠지만, 한 논문에서는 새로운 evaluation metric을 
제시하면서 CAM이 나온 이후로 큰 발전이 없었다고 주장하기도 하였습니다. 즉 CAM과 Grad-CAM은 구현하기도 매우 쉽지만 성능도 매우 우수한 것으로 받아들일 수 있고, 
visual task에서 다양하게 사용될 수 있는 범용성 높은 논문이라고 생각합니다. (논문들에서 네트워크의 성능을 CAM으로 보여주기도 합니다.)&lt;/p&gt;</content><author><name>Nam Hyeon Woo</name></author><category term="review of paper" /><summary type="html">CAM</summary></entry><entry><title type="html">Cut and Paste, GAN</title><link href="http://localhost:4000/review%20of%20paper/paper-review-copy-past-gan/" rel="alternate" type="text/html" title="Cut and Paste, GAN" /><published>2020-11-22T00:00:00+09:00</published><updated>2020-11-22T00:00:00+09:00</updated><id>http://localhost:4000/review%20of%20paper/paper-review-copy-past-gan</id><content type="html" xml:base="http://localhost:4000/review%20of%20paper/paper-review-copy-past-gan/">&lt;h2 id=&quot;weakly-supervised-segment&quot;&gt;Weakly supervised segment&lt;/h2&gt;

&lt;h5 id=&quot;paper&quot;&gt;Paper&lt;/h5&gt;
&lt;p&gt;Remez, Tal, et al. “Learning to Segment via Cut-and-Paste”, ECCV, 2018&lt;/p&gt;

&lt;h5 id=&quot;proposition&quot;&gt;Proposition&lt;/h5&gt;
&lt;p&gt;이 논문은 Weakly supervised 방법으로 instance segmentation하는 방법을 제안하고 있습니다. Bounding box가 주어졌다고 가정하며, Faster R-CNN의 
features를 사용하여 GAN을 학습시킵니다. 논문 제목에서 Cut and Past라는 용어를 사용하는데, Method에서 왜 이러한 용어를 사용하는 지 설명하도록 하겠습니다. 
이전에 포스팅하였던 CAM에서는 class label를 사용하여 weakly supervised object localization을 하였는데, 이 논문에서는 좀 더 라벨링 비용이 큰 
bounding box를 사용하고 있습니다.&lt;/p&gt;

&lt;h5 id=&quot;method&quot;&gt;Method&lt;/h5&gt;
&lt;p&gt;&lt;img src=&quot;/assets/imgs/cut-and-past-gan.png&quot; alt=&quot;&quot; /&gt;
방법은 간단하지만 창의적입니다. 먼저 이미지에서 물체와 배경을 cut합니다. Generator는 Faster RCNN과 Mask prediction head로 이루어져 있고, cut한 물체의 
mask를 estimation하는 task를 수행합니다. 추정한 mask를 이용하여 배경과 물체를 합성하고 discriminator를 이용하여 학습이 진행됩니다. Discriminator는 
cut and paste한 이미지와 자연스러운 이미지를 구분하려고하고, generator는 discriminator를 속이고자합니다. Generator가 Discriminator를 속이기 위해서 
물체를 더 잘 뜯어낼 수 있도록 mask를 추정해야합니다. 추정한 mask가 물체와 정확하게 맞지 않다면, 이미지를 합성하였을 때 어색한 부분이 있을 것이고 discriminator는 
보다 쉽게 구분할 수 있을 것이기 때문입니다.&lt;/p&gt;

&lt;p&gt;어느 배경에 paste할 것인가는 중요한 문제일 수 있습니다. 논문에서는 uniform pasting과 depth sensitive pasting 방법을 실험하고 있습니다. 또한, degenerate solutions이 
존재하고 이를 방지할 수 있어햐 합니다. 가장 쉽게 생각할 수 있는 degenerate solutions은 mask가 모두 1이거나 0인 경우가 있습니다. mask가 0이거나 1이면 
합성이 일어나지 않았기 때문에 합성한 이미지는 모두 자연스러운 이미지일 것입니다. Mask가 1인 경우에는 주변 context를 제공하여 해결하였으며, mask가 0인 경우는 
물체의 유무를 분류하는 것을 명시적으로 수행합니다. Classifier를 통해서 mask가 물체가 없는 경우, 값이 모두 0인 경우를 방지합니다. 최종 손실 함수는 다음과 같이 표현됩니다.
$$
L = L_{CPGAN} + w_{cls}L_{CLS}.
$$&lt;/p&gt;

&lt;h2 id=&quot;unsupervised-object-discovery&quot;&gt;Unsupervised object discovery&lt;/h2&gt;

&lt;h5 id=&quot;paper-1&quot;&gt;Paper&lt;/h5&gt;
&lt;p&gt;Arandjelović, Relja, and Andrew Zisserman. “Object discovery with a copy-pasting gan.”, arXiv, 2019&lt;/p&gt;

&lt;h5 id=&quot;proposition-1&quot;&gt;Proposition&lt;/h5&gt;
&lt;p&gt;위 논문과 달리 이 논문에서는 boundig box도 사용하지 않는 unsupervised 방법으로 접근합니다. 위 논문과 마찬가지로 pasting 방식을 통해서 이미지에서 object를
찾고자 합니다. Generator가 실패하는 것을 위 논문에서는 degenerate solutions이라고 표현하였는데, 이 논문에서는 네트워크가 cheating하는 것이라고 표현하고 있습니다. 
Cheating을 막기위해서 다양한 방식을 제안합니다.&lt;/p&gt;

&lt;h5 id=&quot;method-1&quot;&gt;Method&lt;/h5&gt;
&lt;p&gt;Source와 destination 이미지가 존재하고 source에 있는 물체를 destination에 pasting하는 것이 task입니다. cut-past와 마찬가지로 mask를 물체에 맞게 
추정해야 discriminator를 속일 수 있습니다. Generator의 Cheating을 막기위해서 Source에서 추정한 mask를 무관한 이미지에 적용하여 이미지를 합성합니다. 그리고 generator는 
fake information으로 네트워크를 학습하게 됩니다. Discriminator의 경우에는 edge에서 일어나는 사소한 아티팩트에 집중하는 네트워크가 될 수 있습니다. 이를 방지하기 
위해서 이미지를 blur합니다. 또한, 처음에 아무 정보도 없는 mask로부터 학습하지 않는 것을 방지하기 위해서 gounded fake를 임의로 만들어서 학습하도록 합니다.&lt;/p&gt;

&lt;h5 id=&quot;etc&quot;&gt;etc&lt;/h5&gt;
&lt;p&gt;GAN은 임의의 데이터의 분포를 학습할 수 있어 다양한 곳에서 adversarial loss가 사용되고 있는 것 같습니다. 특히 GAN을 통해서 informatoin을 충분히 줄 수 없는 상황에서도 
강력한 supervision을 만들어낼 수 있습니다. GAN은 학습시키기 어렵다는 단점이 존재하엿는데 최근에 많은 연구가 이루어졌습니다. 다양한 분야에서 adversarial loss를 사용할 수 있는 것은 
강력한 도구라고 생각합니다.&lt;/p&gt;</content><author><name>Nam Hyeon Woo</name></author><category term="review of paper" /><summary type="html">Weakly supervised segment</summary></entry></feed>